package opt.test;

import opt.*;
import opt.example.*;
import opt.ga.*;

import shared.*;
import func.nn.backprop.*;

//Java imports
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.*;
import java.io.*;
import java.text.*;
import java.lang.Runnable;
import java.lang.Thread;
import java.lang.reflect.Array;

public class LetterTest {
	private static String outputDir = "./EyeResults";
	private Thread t;
	private String threadName;
	private String optimizationAlgorithm;

	private String training_data_file;
	private String output_dir;
	private Instance[] training_instances;
	private static Instance[] test_instances;
	private DataSet training_set;
	private String comments;

	private int trainingIterations;

	//ANN specifications
	private static int inputLayer;
	private static int outputLayer;
	private static int hiddenLayer;


	private DecimalFormat df = new DecimalFormat("0.000");

	private static enum Algorithm {
		RHC, SA, GA, MIMIC
	};








	private static class LetterOptimization implements Runnable {
		
		private double[] calculate_accuracy(Instance[] instances, Instance optimalInstance) {
			int correct = 0, incorrect = 0;
			BackPropagationNetwork network = new BackPropagationNetworkFactory().createClassificationNetwork(new int[] {inputLayer, hiddenLayer, outputLayer});
			network.setWeights(optimalInstance.getData());
			for(int j = 0; j < instances.length; j++) {
				network.setInputValues(instances[j].getData());
				network.run();

				double predicted = Double.parseDouble(instances[j].getLabel().toString());
				double actual = Double.parseDouble(network.getOutputValues().toString());

				double trash = Math.abs(predicted - actual) < 0.5 ? correct++ : incorrect++;
			}
			double[] A = {correct,incorrect,correct*100.0/(correct+incorrect)};
			return A;
		}
		private  ErrorMeasure measure = new SumOfSquaresError();
		private double[] convert_to_double_arr(String[] str_array) {
			double[] double_arr = new double[str_array.length];
			for (int i=0; i < str_array.length; i++) {
				double_arr[i] = Double.parseDouble(str_array[i]);
			}
			return double_arr;
		}
		private Instance[] initializeInstances(String data_file) {

			Instance[] instances = null;

			try {
				ArrayList<String []> instance_list = new ArrayList();
				String line;
				BufferedReader br = new BufferedReader(new FileReader(new File(data_file)));
				while ((line = br.readLine()) != null) {
					instance_list.add(line.split(","));
				}

				instances = new Instance[instance_list.size()];

				for(int i = 0; i < instances.length; i++) {
					double[] attributes = convert_to_double_arr(instance_list.get(i));
					instances[i] = new Instance(Arrays.copyOfRange(attributes, 0, attributes.length - 1)); // Create an instance with the attributes
					instances[i].setLabel(new Instance(attributes[attributes.length - 1])); // Set the label for each instance
				}
			}
			catch (Exception e) {
				e.printStackTrace();
			}
			return instances;
		}
		//Prepare instances and dataset
		private Instance[] training_instances ;
		private DataSet training_set ;
		private Instance [] test_instances;



		public LetterOptimization(Algorithm algorithm, HashMap<String, Double> params) {
			training_instances = initializeInstances("/home/ghusson/Documents/GTL/Machine_Learning/project2/src/opt/test/eye_train.csv");
			test_instances = initializeInstances("/home/ghusson/Documents/GTL/Machine_Learning/project2/src/opt/test/eye_test.csv");
			training_set = new DataSet(training_instances);
			this.algorithm = algorithm;
			this.params = params;
			inputLayer = training_instances[0].size() - 1;
			outputLayer = 1;
			hiddenLayer = (int)(inputLayer + outputLayer)/2;
		}
		//ANN specifications
		private int inputLayer ;
		private int outputLayer ;
		private int hiddenLayer;
		// TODO Auto-generated constructor stub
		private Algorithm algorithm;
		private DecimalFormat df = new DecimalFormat("0.000");
		private HashMap<String, Double> params;
		private void LetterOptimizationRHC() {
			String results = "";
			BackPropagationNetwork network = new BackPropagationNetworkFactory().createClassificationNetwork(new int[] {inputLayer, hiddenLayer, outputLayer});
			NeuralNetworkOptimizationProblem nnop = new NeuralNetworkOptimizationProblem(training_set, network, measure);
			OptimizationAlgorithm oa =new RandomizedHillClimbing(nnop);

			double time_training=0;
			for(int k = 1; k <= params.get("iterations").intValue(); k++) {
				results += k + ",";
				double start = System.nanoTime();
				double error = 1/oa.train();
				double end = System.nanoTime();
				time_training += (end - start)/Math.pow(10,9);
				results += df.format(error) + ",";
				double start_test = System.nanoTime();
				Instance optimalInstance = oa.getOptimal();
				double end_test=System.nanoTime();
				double time_testing=(end_test - start_test)/Math.pow(10, 9);
				double[] training_accuracy = calculate_accuracy(training_instances, optimalInstance) ;
				String pourcentage_training = df.format(training_accuracy[2]/100.0f);
				double[] test_accuracy = calculate_accuracy(test_instances, optimalInstance);
				String correct_test=df.format(test_accuracy[0]);
				String incorrect_test=df.format(test_accuracy[1]);
				String pourcentage_test=df.format(test_accuracy[2]/100.0f);
				String trainingTime = df.format(time_training);
				String testingTime = df.format(time_testing);
				results += pourcentage_training + ",";
				results += trainingTime + ",";
				results += correct_test + ",";
				results += incorrect_test + ",";
				results += pourcentage_test + ",";
				results += testingTime + "\n";
			}


			Utils.writeOutputToFile(outputDir, "diabetesRHC.csv", results);
			System.out.println("  RHC terminated run " + params.get("run").intValue());
		}

		private void LetterOptimizationSA() {
			String results = "";
			BackPropagationNetwork network = new BackPropagationNetworkFactory().createClassificationNetwork(new int[] {inputLayer, hiddenLayer, outputLayer});
			NeuralNetworkOptimizationProblem nnop = new NeuralNetworkOptimizationProblem(training_set, network, measure);
			OptimizationAlgorithm oa =new SimulatedAnnealing(1E11, .95, nnop);

			double time_training=0;
			for(int k = 1; k <= params.get("iterations").intValue(); k++) {
				results += k + ",";
				double start = System.nanoTime();
				double error = 1/oa.train();
				double end = System.nanoTime();
				time_training += (end - start)/Math.pow(10,9);
				results += df.format(error) + ",";
				double start_test = System.nanoTime();
				Instance optimalInstance = oa.getOptimal();
				double end_test=System.nanoTime();
				double time_testing=(end_test - start_test)/Math.pow(10, 9);
				double[] training_accuracy = calculate_accuracy(training_instances, optimalInstance) ;
				String pourcentage_training = df.format(training_accuracy[2]/100.0f);
				double[] test_accuracy = calculate_accuracy(test_instances, optimalInstance);
				String correct_test=df.format(test_accuracy[0]);
				String incorrect_test=df.format(test_accuracy[1]);
				String pourcentage_test=df.format(test_accuracy[2]/100.0f);
				String trainingTime = df.format(time_training);
				String testingTime = df.format(time_testing);
				results += pourcentage_training + ",";
				results += trainingTime + ",";
				results += correct_test + ",";
				results += incorrect_test + ",";
				results += pourcentage_test + ",";
				results += testingTime + "\n";
			}


			Utils.writeOutputToFile(outputDir, "KnapsackSA_IT" + params.get("SA_initial_temperature") + "_CF"
					+ params.get("SA_cooling_factor") + ".csv", results);
			System.out.println("  RHC terminated run " + params.get("run").intValue());
		}

		private void LetterOptimizationGA() {
			String results = "";
			BackPropagationNetwork network = new BackPropagationNetworkFactory().createClassificationNetwork(new int[] {inputLayer, hiddenLayer, outputLayer});
			NeuralNetworkOptimizationProblem nnop = new NeuralNetworkOptimizationProblem(training_set, network, measure);
			OptimizationAlgorithm oa =new RandomizedHillClimbing(nnop);

			double time_training=0;
			for(int k = 1; k <= params.get("iterations").intValue(); k++) {
				results += k + ",";
				double start = System.nanoTime();
				double error = 1/oa.train();
				double end = System.nanoTime();
				time_training += (end - start)/Math.pow(10,9);
				results += df.format(error) + ",";
				double start_test = System.nanoTime();
				Instance optimalInstance = oa.getOptimal();
				double end_test=System.nanoTime();
				double time_testing=(end_test - start_test)/Math.pow(10, 9);
				double[] training_accuracy = calculate_accuracy(training_instances, optimalInstance) ;
				String pourcentage_training = df.format(training_accuracy[2]/100.0f);
				double[] test_accuracy = calculate_accuracy(test_instances, optimalInstance);
				String correct_test=df.format(test_accuracy[0]);
				String incorrect_test=df.format(test_accuracy[1]);
				String pourcentage_test=df.format(test_accuracy[2]/100.0f);
				String trainingTime = df.format(time_training);
				String testingTime = df.format(time_testing);
				results += pourcentage_training + ",";
				results += trainingTime + ",";
				results += correct_test + ",";
				results += incorrect_test + ",";
				results += pourcentage_test + ",";
				results += testingTime + "\n";
			}


			Utils.writeOutputToFile(outputDir,
					"knapsackGA_POP" + params.get("GA_population").intValue() + "_MAT"
							+ params.get("GA_mate_number").intValue() + "_MUT"
							+ params.get("GA_mutate_number").intValue() + ".csv",
							results);
			System.out.println("  RHC terminated run " + params.get("run").intValue());
		}
		public void run() {
			switch (algorithm) {
			case RHC:
				LetterOptimizationRHC();
				break;
			case SA:
				LetterOptimizationSA();
				break;
			case GA:
				LetterOptimizationGA();
				break;

			}
		}
	}
	public static void main(String[] args) throws InterruptedException {
		Locale.setDefault(new Locale("en", "US"));
		ArrayList<Thread> threads = new ArrayList<Thread>();
		HashMap<String, Double> params = new HashMap<String, Double>();
		int runs = 10;

		for (int i = 1; i <= runs; i++) {
			params.put("run", (double) i);

			params.put("iterations", 100.);
			threads.add(new Thread(new LetterOptimization(Algorithm.RHC, new HashMap<String, Double>(params))));

			params.put("SA_initial_temperature", 100.);
			params.put("SA_cooling_factor", .95);
			params.put("iterations", 100.);
			threads.add(new Thread(new LetterOptimization(Algorithm.SA, new HashMap<String, Double>(params))));

			params.put("GA_population", 100.);
			params.put("GA_mate_number", 50.);
			params.put("GA_mutate_number", 10.);
			params.put("iterations", 100.);
			threads.add(new Thread(new LetterOptimization(Algorithm.GA, new HashMap<String, Double>(params))));
			
		}

		System.out.println("Start to compute ANN optimisation");
		for (Thread t : threads) {
			t.start();
		}
		for (Thread t : threads) {
			t.join();
		}
		System.out.println(" ANN optimisation computation terminated");
	}

}



